## **Week 3 - Optimizer/Embedding**
- **Topic**
  - Dropout
  - Embedding
  - Positional Encoding
  - Optimizers (SGD, momentum, Adam)
- **Week 3 Exercise**
  - Compare NumPy model accuracy with different Optimizers

</br>

## Exercise Description
- main.py train 3 same models by fashon-mnist dataset
- each training method has different optimizers.
- fill blank of SGD, SGD-with-momentum, Adam
- compare accuracy with different optimizers

</br>

## Excepted output

- SGD
![week_3_output_1](https://github.com/naye971012/numpy_transformer/assets/74105909/e2e03971-22d1-40b2-9273-9ae9d2972b04)

- SGD_with_momenum
![week_3_output_2](https://github.com/naye971012/numpy_transformer/assets/74105909/2763d446-8f52-4d44-8a2c-6e79f629bb6a)

- Adam
![week_3_output_3](https://github.com/naye971012/numpy_transformer/assets/74105909/20400aa5-30b2-4799-8125-506b10e5a108)


- since we use mlp model, overall accuracy is low
